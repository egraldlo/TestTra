Hadoop IO
1，数据完整性
  用CRC计算数据校验和，CRC校验在C++中也能使用吗？用什么包呢？
2，HDFS的数据完整性
  针对io.bytes.per.chechsum指定字节的数据计算校验和，默认是512字节
  
  
  
  
  
Hadoop HDFS
1，hdfs是为高吞吐量优化的，不合是低延时的作业，如果有低延时的需求，就用HBase。
2，namenode将文件系统的元数据存放在内存中。
3，HDFS的写操作总是将数据添加到文件的末尾。
4，HDFS中小于一个块大小的文件不会占据整个块的空间。块为什么是64M呢，首先设置的太大不能达到并行的
   效果，然后设置的太小不利于最小化寻址开销。
5，md5sum命令来检测两个文件是否完全一样，能用md5算法还原一个字符串原来是什么样的吗
   hadoop源码FileSystem接口：
   public abstract class FileSystem extends Configured implements Closeable
   mapreduce可以使用本地文件系统，但是最好还是要数据本地优化的分布式文件系统，比如hdfs或者kfs
6，
